<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Web Media Application Developer Guidelines</title>
    <script
     src="https://www.w3.org/Tools/respec/respec-w3c-common"
     class='remove'></script>
    <script class="remove">
      var respecConfig = {
        specStatus: "CG-DRAFT",
        editors: [{
          name: "Jeff Burtoft",
          url: "mailto:jeffburt@microsoft.com",
          company: "Microsoft",
          companyURL: "http://www.microsoft.com"
        }],
        processVersion: 2015,
        edDraftURI: "http://w3c.github.io/webmediaguidelines",
        shortName: "dahut",
        wg: "Web Media API Community Group",
        wgURI: "https://www.w3.org/community/webmediaapi/",
      };
    </script>
  </head>
  <body>
    <section id="abstract">
      <p>
        This specification companion guide to the Web Media API spec. While the Web Media API spec is targeted at device implementations to support media web apps in 2017, this specification will outline best practices and developer guidance for implementing web media apps. This specification should be updated at least annually to keep pace with the evolving Web platform. The target devices will include any device that runs a modern HTML user agent, including televisions, game machines, set-top boxes, mobile devices and personal computers.
      </p>
      <p>
        The goal of this Web Media API Community Group specification is to transition to the W3C Recommendation Track for standards development.
      </p>
    </section>
    <section id="sotd"></section>
    <section>
      <h2>Introduction</h2>
      <ol class="ednote" title="Notes on v1 draft specification:">
        <li>This document is directed towards application developers.  Its content will contain best practices for building media applications across devices, it will not direction to device manufactures or User Agent implementers. </li>
        <li>This is a companion spec put forth by the Web Media API Community Group.</li>
      </ol>
      <h3>Scope</h3>
      <p></p>
      <h3>Definitions</h3>
      <p>TBD</p>
   </section>
   <section>
      <h2>Media Playback Use Cases</h2>
      <p>
      </p>
      <section>
            <h3>Streaming overview</h3>
            <p>
              NOTE: Adding a brief introductory section that removes the need for duplication of material across VOD and linear sections. Here we can outline the broad mechanics that are shared by the two use cases allowing us to focus on the distinctions in the respective sections.
            </p>
            <h4>General Description</h4>
            <p>Material (typically in video or audio content) is made available by a content provider via a web-enabled application and delivered by a content distribution network. There are three distinct interlocking processes: generation, delivery and consumption / playback.
            </p>
            <h4>Content Generation</h4>
            <p>
               Original Content is normally delivered to the service provider as a file with near lossless compression (eg 25mbps to 100mbps).
            </p>
            <p>
              Streaming content is generated by encoding the source against an encoding profile. Firstly, the content is duplicated into different versions of the file that target delivery over a connection that achieves a certain bandwidth, these are the different bitrates. After this is it split into segments of specified length.
            </p>
            <p>
              The first process is defined by an encoding profile. A profile describes the set of constraints to be used when video is being prepared for consumption by a range of video applications. The description includes the different bitrates to be generated during the encoding process that will allow for the same content to be consumed on a wide variety of devices on different networks from cellular to LAN.
            </p>
            <p>
              The second process is performed by a packager which segments the different bitrates. These are then packaged into a transport format such as transport streams (.ts) or fragmented mp4s (.m4s) after this they are encrypted with a DRM that is suitable for the environment where the content is going to be played out. The packager is also responsible for the generation of a manifest file, typically a DASH (.mpd), HLS (.m3u8) or possibly Smooth (.ism) or HDS (.f4v), that specifies the location of the media and its format.
            </p>
            <h4>Content Delivery</h4>
            <p>
              After the content has been generated the resulting segments of video and corresponding manifest files are pushed to an origin server. However, the assets are rarely delivered directly from the origin.
            </p>
            <p>
              At this stage, the control in the chain switches to the client's web video application. The content provider supply's the client with the URL of a manifest file located on a CDN rather than the origin. /
              The manifest is typically passed to a player. The player makes a GET request for the manifest from CDN edge, its location is determined by DNS. The CDN does one of two things: if it has the asset it returns it to the player, if it does not it requests it from the origin. When it receives it the CDN caches the manifest for use by other sessions and then then returns it to the requesting client.
            </p>
            <h4>Content Playback</h4>
            <p>
              The player parses the manifest. At this point the behavior differs between players found on the different devices depending on the transport formats. However, broadly, it behaves in the following way: <br>
<ol>
<li>The client uses DRM license URL to request a secure key to enable decoding of the media.</li>
<li>The player's ABR (adaptive bitrate) algorithm determines the bandwidth available to the client by examining the response times associated with the request for the first segment of video, how many bytes were received over what time period. This provides enough information to determine the playback quality that the player can sustain over a proportion of the length of the asset, or in the case of live streaming a specific timeframe. </li>
<li>Once the player has this information it can then compare this with the metadata from the manifest that describes the different qualities that the content provider is supplying. It picks the quality level with an average bitrate that is as close to the available bitrate but within its bounds to avoid a situation where a consistent experience is interrupted as the player requires more data than the current network bandwidth can supply, where the playerâ€™s buffer is emptying faster than it is being filled. </li>
<li>It then requests a segment from a location on the edge server that typically relative to the location of the manifest. </li>
<li>Once it has received the segment it is then typically decrypted in accordance with the specific DRM used. </li>
<li>It then adds it to the player's video buffer. </li>
<li>The media engine pulls the video data from the buffer and passes it to the video surface where it is rendered. </li>
<li>If the available bandwidth remains constant the player will continue to request segments from the same bitrate stream, pulling down chunks and filling its video buffer. In the event a change in network availability the player will make a decision about the need to either drop to a lower bitrate stream or request a higher bitrate child manifest and associated segment. </li>
</ol>
</p>
      </section>
      <section>
            <h3>On-Demand Streaming (VOD)</h3>
            <p>
              Despite the almost identical mechanics used for the two types of content, VOD and linear, the contents generation, delivery and playout a large organsiation will typically maintain two distinct workflows as there are subtle but important ways in which they differ.
            </p>
            <h4>Content Generation</h4>
            <p>
              For VOD the source is typically tape rather than a feed. The encoding profiles are also subtly different. A greater priority can be placed on high quality as the latency, time to live, is not a requirement. To this end the encoder is able to prioritise density over quality via configuration allowing VOD encoders to spend more time on each frame. There are important differences in the manifests created. In HLS there is a tag that tells the player whether the playlist is describing on demand material: #EXT-X-PLAYLIST-TYPE:VOD. As we will see shortly this is used by the player. There are also client side restrictions where certain profiles are blocked due to rights restrictions and network consumption capped bitrates on movies and entertainment whilst being allowed on sports content. Fragments size will also effect playout as a player's ABR can be more responsive if the chunks are smaller, e.g. 2 seconds rather than 10 seconds.
            </p>
            <h4>Content Delivery</h4>
            <p>
              The CDN configuration and topology for delivering VOD content is also different to linear. There are different levels of caching; popular VOD content which is kept closer to the edge in the CDN network in this way it can be delivered to customers faster than an edge server that isn't tuned for high volume delivery. Older and less popular content is retained in mid-tier caching whilst the long tail content is relegated to a lower tier.
            </p>
            <h4>Content Playback</h4>
            <p>
              As mentioned in the content generation section the player uses a tag within the manifest to determine the playout type. In HLS if there is a type is VOD then the player will not reload the manifest. This has important consequences if there are changes in availability after the session as commenced. In DASH the difference between a live and VOD playlist are more subtle (more detail) </p>
              <p>
                There are other differences in playout as well. Unlike linear, a VOD asset has a predefined duration, information around duration and current time can be used to update the UI to provide feedback to the user on the amount and proportion of the asset watched.
              </p>
              <p>
                At a broader level the UX requirements will be different in respect to the need for representing static rather than linear content where a tile view rather an epg (electronic programme guide) is required. There is also a requirement for Trick Play.
              </p>

              <h3>VOD use cases</h3>
<p>
              In the previous section, we outlined the use cases associated with video streaming. In this section, we give some examples of use cases that are specific to on-demand streaming and are mainly related to strategies employed on the clients to improve performance in some way.
            </p>



            <h4> Pre-caching </h4>
               <p>
              The key performance indicator for most streaming services will be the percentage of sessions that experience buffering as a ratio to the length of the session. Buffering, the state of the video application when the player has insufficient content within its framebuffer to continuously play content, within a session has a direct relationship to engagement and as a consequence retention. For every second of buffering within a session 10pc of users abandon a video stream. Pre-caching is a strategy used in on-demand streaming. Web video application developers will use points within an application's UX to pre-cache content, for example when entering a mezzanine/synopsis page the application might connect to a stream and begin to pull content and either add it directly to the playerâ€™s video buffer or alternatively store the chunks locally. The consequence of this is that when or if the user chooses to play the content after reading the synopsis the video will commence playing without buffering and hence provide the user with a preferable experience to a buffering indicator. This technique is used by Netflix, Sky and the BBC in the case of on-demand content being watched in an in-home context. This technique is not used for cellular sessions where userâ€™s mobile data would be consumed potentially on content that they do not watch.
            </p>

            <h4>Client-side ad insertion</h4>

          <p>Client-side ad insertion (CSAI). Typically, this involves using a script available in the client runtime, JavaScript in the case of the web, to insert an advert during the userâ€™s session. As an example, an ad serving vendor provides a client script. Close to the playerâ€™s initiation the client library makes its api available. The web application listens to events associated with playback, for example the video elements media event â€˜playingâ€™. The web application then calls the DOM pause method on the video element and then calls the play method provided by the client-side ad library, passing it the â€˜idâ€™ of the video asset. This is then returned to the vendor, possibly along with other identifiers that can be used to target the audience with a specific ad. At this stage an auction is performed with business logic at the ad vendor determining which provider supplies the ad (this is a complex topic and outside the scope of this document). The vendor responds with a VAST (Video Ad Serving Template) payload that includes the URI of the ad content appropriate for the playback environment. In some cases, there is no ad, if this is the case the user is presented with the content they originally requested and control is passed back to the web video application. If there is an ad targeted against the content then the library performs DOM manipulation and injects a new video element into the document this is typically accompanied by a further script that provides the vendor with insights based on the current session. The ad plays. The ad object will conform to VPAID (Video Player Ad Serving Definition) and present a standardised interface to the player for possible interaction, it will issue a standard set of events which the web application can listen to. In response to an â€˜adEndedâ€™ event the local library will tear down the injected DOM elements and in turn issue an event that the web application can use to trigger a return to playing the original content.

              In the case of live linear CSAI web socket technology is often used. If the content has a dynamic nature, for example a sports event or a fashion show, a web socket connection is established and ads can then be â€˜pushedâ€™ when the editorial team thinks itâ€™s appropriate. The web video application listens to the library that establishes and manages the connection. An event is pushed to the listening clients simultaneously, this event is then used to trigger the same set of events discussed above.

            </p>



            <h4>Other possible VOD use cases</h4>
            <ul>
              <li>Buffer manipulation (device / storage dependent)</li>
              <li>HTTP byte range requests</li>
              <li>HTTPs support</li>
              <li>Player event exposure</li>
              <li>HDCP security requirement for HDMI</li>
              <li>Watermarking</li>
              <li>Hardware acceleration support</li>
            </ul>


            </p>




      </section>
      <section>
            <h3>Live Streaming</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>Live Streaming with Server Side Ad Insertion</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>Live Streaming with Client Side Ad Insertion</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>Live Linear Streaming</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>Live Linear Streaming with Client Side Ad Insertion</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>On-Demand Streaming with Trick Mode</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>Live Streaming with Trick Mode</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>On-Demand Streaming with Thumbnail Navigation</h3>
            <p>TBD
            </p>
      </section>
      <section>
            <h3>Live Streaming with Thumbnail Navigation</h3>
            <p>TBD
            </p>
      </section>

   </section>
   <section>
      <h2>Media Playback Methods</h2>
      <p>TBD
      </p>
      <section>
        <h3>Device Identification</h3>
        <p>Device identification is required both at the level of device type and family and also to uniquely identify a device. Different techniques are used in different environments.</p>
        <h4>Device Type</h4>
        <p>In the context of a mobile client the broad device type is already known - you canâ€™t install an Android client on an iOS device. However, operating systems evolve and are extended. Within an the application layer you will still need to determine the level of support for feature X and branch your code accordingly. <br>

If the application is hosted or the same application is deployed via different app stores then the clients runtime could be more ambiguous. The classic approach is to use the navigator.userAgent. Whilst this returns a string that does not explicitly state the device by name a regular expression match can be used to look for patterns that can confirm the device family. As an example the name â€˜Tizenâ€™ can be found in the user agent strings for Samsung and â€˜netcastâ€™ for LG devices. In the Chrome browser the strings will be different on windows, mac, android and webview.<br>

Another method similar to feature detection is to look for available APIs, many of these are unique to a device, for example if(tizenGetUser){ then do X }.</p>

<h4>Unique device Identifier</h4>
<p>After you have determined what type of device you are on you need to be able to identify that device uniquely. Most device manufacturers provide an API so once you have discovered what type of device you are on you then know what APIâ€™s will be available to you. Each manufacturer provides a string constructed in a different way, some use the serial number of the device itself whilst others use lower level unique identifiers taken from the hardware. In each case the application layer should attempt to namespace this in some way to avoid an unlikely, but theoretically possible, clash with another user in any server-side database of users and devices.<br>

In a classic pc /browser, rather that mobile or stb, environment there are technical issues with using unique identifiers as a user can access these stored locally and either delete them or reuse them in another context, this could allow them to watch content on more devices than their user account allows. For this reason some vendors prefer to use DRM solutions that both create and encrypt unique identifiers in a way that obscures them from the user.</p>


      </section>
      <section>
        <h3>Device Media Profile Support</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Device Key System Support</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Device Content Protection Capabilities</h3>
        <p>How to determine the content protection capabilities of a device.
        </p>
      </section>
      <section>
        <h3>Using Encrypted Media Extensions</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Using Media Source Extensions</h3>
        <p>TBD
        </p>
      </section>

   </section>
   <section>
      <h2>Content Encoding Guidelines</h2>
      <p>
      </p>
      <section>
        <h3>For On-Demand Streaming</h3>
        <p>TBD
        </p>
        <section>
          <h4>Media Encoding</h4>
          <p>TBD</p>
        </section>
        <section>
          <h4>Manifest Preparation</h4>
          <p>TBD</p>
        </section>
      </section>
      <section>
        <h3>For Live Streaming</h3>
        <p>TBD
        </p>
        <section>
          <h4>Media Encoding</h4>
          <p>TBD</p>
        </section>
        <section>
          <h4>Manifest Preparation</h4>
          <p>TBD</p>
        </section>
      </section>
      <section>
        <h3>Ad Encoding for On-demand Content</h3>
        <p>TBD
        </p>
        <section>
          <h4>Media Encoding</h4>
          <p>TBD</p>
        </section>
        <section>
          <h4>Manifest Preparation</h4>
          <p>TBD</p>
        </section>
      </section>
      <section>
        <h3>Ad Encoding for Live Streaming with Server Side Ad-insertion</h3>
        <p>TBD
        </p>
        <section>
          <h4>Media Encoding</h4>
          <p>TBD</p>
        </section>
        <section>
          <h4>Manifest Preparation</h4>
          <p>TBD</p>
        </section>
      </section>
      <section>
        <h3>Trick Mode Track</h3>
        <p>TBD
        </p>
        <section>
          <h4>Media Encoding</h4>
          <p>TBD</p>
        </section>
        <section>
          <h4>Manifest Preparation</h4>
          <p>TBD</p>
        </section>
      </section>
      <section>
        <h3>Thumbnails Track </h3>
        <p>TBD
        </p>
        <section>
          <h4>Media Encoding</h4>
          <p>TBD</p>
        </section>
        <section>
          <h4>Manifest Preparation</h4>
          <p>TBD</p>
        </section>
      </section>

   </section>
   <section>
      <h2>Sample Applications</h2>
      <p>
      </p>
      <section>
        <h3>On-Demand Streaming</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Live Streaming</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Live Streaming with Server Side Ad Insertion</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Live Streaming with Client Side Ad Insertion</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Live Linear Streaming</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Live Linear Streaming with Client Side Ad Insertion</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>On-Demand Streaming with Trick Mode</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Live Streaming with Trick Mode</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>On-Demand Streaming with Thumbnail Navigation</h3>
        <p>TBD
        </p>
      </section>
      <section>
        <h3>Live Streaming with Thumbnail Navigation</h3>
        <p>TBD
        </p>
      </section>


   </section>
  </body>
</html>
